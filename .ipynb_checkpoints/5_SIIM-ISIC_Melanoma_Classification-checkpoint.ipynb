{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of SIIM-ISIC Melanoma Classification Metadata and Images\n",
    "\n",
    "# Introduction\n",
    "\n",
    "## The Competition\n",
    "\n",
    "Skin cancer is common cancer type and despite beign mostly non malignant, due to high case numbers it's pretty serious diasease and can lead serious cases if not detected, treated in time. It's usually diagnosed by eye for primarily and followed by further clinical analysis if needed. Even though the rares outcome is called melanoma it's the most deadly one, so early detection is pretty important. For this task using computer aided diagnosis might be helpful for primarily steps and early detections. Better detection might save thousands of lives.\n",
    "\n",
    "This competition might help reaching that goal and I hope it can help people around the world...\n",
    "\n",
    "## Updates:\n",
    "\n",
    "### 23/07/2020:\n",
    "- Added adversarial validation,\n",
    "- Updated metadata by removing biased features,\n",
    "- Created simplier machine learning model.\n",
    "\n",
    "### 25/07/2020:\n",
    "- Added deep learning part\n",
    "- Included EfficientNet modelling\n",
    "- Ensembled metadata and EffNet predictions\n",
    "\n",
    "### 01/01/2020:\n",
    "- Added external [notebook with past years tabular data here](https://www.kaggle.com/datafan07/eda-modelling-of-the-external-data-inc-ensemble)\n",
    "- Small fixes\n",
    "\n",
    "\n",
    "## About the Notebook\n",
    "\n",
    "First of all this is **pretty early version of this notebook**, I decided to start part by part before I fully commit my submission, so for now this notebook covers such as:\n",
    "\n",
    "- EDA of the metadata,\n",
    "- Extracting basic image attributes like image size, colors etc.\n",
    "- Creating new features from existing data,\n",
    "- Design a machine learning model by using these simple features\n",
    "- Make predictions using our model and tabular data\n",
    "- Deep learning part will be added in future...\n",
    "\n",
    "I think using metadata for understanding the problem is really important and plus side is we can use it to improve our scores, for now we only going to use tabular data for submissions. This way we can see it's power and it can help us with future CNN modelling. This notebook going to try answer questions like these:\n",
    "\n",
    "- How's the data looking?\n",
    "- Do we have complete dataset?\n",
    "- How's the target distribution looking? Is it balanced?\n",
    "- What are the effects of scan site on outcome?\n",
    "- Does age effects skin lesion type?\n",
    "- Is there difference between female and male patients in terms of target?\n",
    "- How many unique patient data we have and how many scans they had? Is it important?\n",
    "- Is image quality, colors, size have meaningful impact on the outcome?\n",
    "- Can we see similar observations when we analyse both train and test dataset, if not why?\n",
    "- And much more...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Impressions and Getting Tools Ready\n",
    "\n",
    "Let's buckle up and get our tools ready for our work! We start with importing neccesary libraries. Since we going to do mostly EDA our libraries are going to be related with tabular data and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# loading packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "#\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "#\n",
    "\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "\n",
    "from pandas_summary import DataFrameSummary\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore') # Disabling warnings for clearer outputs\n",
    "\n",
    "\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set some custom styling with our notebook for aesthetics..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting color palette.\n",
    "orange_black = [\n",
    "    '#fdc029', '#df861d', '#FF6347', '#aa3d01', '#a30e15', '#800000', '#171820'\n",
    "]\n",
    "\n",
    "# Setting plot styling.\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting file paths for our notebook:\n",
    "\n",
    "base_path = '/kaggle/input/siim-isic-melanoma-classification'\n",
    "train_img_path = '/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'\n",
    "test_img_path = '/kaggle/input/siim-isic-melanoma-classification/jpeg/test/'\n",
    "img_stats_path = '/kaggle/input/melanoma2020imgtabular'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data\n",
    "\n",
    "We'll continue by loading metadata we're given. Train data has 8 features, 33126 observations and Test data 5 features, 10982 observations.\n",
    "\n",
    "#### Train Dataset Consists Of:\n",
    "\n",
    "1. image name -> the filename of specific image for the train set\n",
    "2. patient_id -> identifies the unique patient\n",
    "3. sex -> gender of the patient\n",
    "4. age_approx -> approx age of the patient at time of scanning\n",
    "5. anatom_site_general_challenge -> location of the scan site\n",
    "6. diagnosis -> information about the diagnosis\n",
    "7. benign_malignant - indicates scan result if it's malignant or benign\n",
    "8. target -> same as above but better for modelling since it's binary\n",
    "\n",
    "And the next dataset we going to inspect test. It has same features as train set except for scan results, well that's why it's test set right?!\n",
    "\n",
    "#### Test Dataset Consists Of:\n",
    "\n",
    "1. image name -> the filename of specific image for the train set\n",
    "2. patient_id -> identifies the unique patient\n",
    "3. sex -> gender of the patient\n",
    "4. age_approx -> approx age of the patient at time of scanning\n",
    "5. anatom_site_general_challenge -> location of the scan site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning to Neural Networks\n",
    "\n",
    "This part we gonna train more complicated models by using images themselves. For this part I was inspired by AgentAuers's 'Incredible TPUs' [here](https://www.kaggle.com/agentauers/incredible-tpus-finetune-effnetb0-b6-at-once). It's a great notebook and you should check that, again thanks for AgentAuers for letting me use some of his code as baseline for this part of the notebook! Also thanks to Chris Deotte for great datasets with tfrecords! \n",
    "\n",
    "We start by importing neccesary packages and setting random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import efficientnet.tfkeras as efn\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "tf.random.set_seed(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading image storage buckets\n",
    "\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path('melanoma-384x384')\n",
    "\n",
    "filenames_train = np.array(tf.io.gfile.glob(GCS_PATH + '/train*.tfrec'))\n",
    "filenames_test = np.array(tf.io.gfile.glob(GCS_PATH + '/test*.tfrec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to TPU...\n",
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "Initializing  TPU...\n",
      "TPU initialized\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "# Setting TPU as main device for training, if you get warnings while working with tpu's ignore them.\n",
    "\n",
    "DEVICE = 'TPU'\n",
    "if DEVICE == 'TPU':\n",
    "    print('connecting to TPU...')\n",
    "    try:        \n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "        print('Could not connect to TPU')\n",
    "        tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        try:\n",
    "            print('Initializing  TPU...')\n",
    "            tf.config.experimental_connect_to_cluster(tpu)\n",
    "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "            print('TPU initialized')\n",
    "        except _:\n",
    "            print('Failed to initialize TPU!')\n",
    "    else:\n",
    "        DEVICE = 'GPU'\n",
    "\n",
    "if DEVICE != 'TPU':\n",
    "    print('Using default strategy for CPU and single GPU')\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "if DEVICE == 'GPU':\n",
    "    print('Num GPUs Available: ',\n",
    "          len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "print('REPLICAS: ', strategy.num_replicas_in_sync)\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set config for our next steps. You can play with these but mind the memory sizes with the batches & image sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can edit these settings.\n",
    "\n",
    "cfg = dict(\n",
    "           epochs=18,\n",
    "           batch_size=32,\n",
    "           img_size=384,\n",
    "           lr_start=0.000005,\n",
    "           lr_max=0.00000125,\n",
    "           lr_min=0.000001,\n",
    "           lr_rampup=5,\n",
    "           lr_sustain=0,\n",
    "           lr_decay=0.8,\n",
    "           \n",
    "    \n",
    "           transform_prob=1.0,\n",
    "           rot=180.0,\n",
    "           shr=2.0,\n",
    "           hzoom=8.0,\n",
    "           wzoom=8.0,\n",
    "           hshift=8.0,\n",
    "           wshift=8.0,\n",
    "    \n",
    "           optimizer='adam',\n",
    "           label_smooth_fac=0.05,\n",
    "           tta_steps=20\n",
    "            \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift,\n",
    "            width_shift):\n",
    "    \n",
    "    ''' Settings for image preparations '''\n",
    "\n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear = math.pi * shear / 180.\n",
    "\n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1], dtype='float32')\n",
    "    zero = tf.constant([0], dtype='float32')\n",
    "    rotation_matrix = tf.reshape(\n",
    "        tf.concat([c1, s1, zero, -s1, c1, zero, zero, zero, one], axis=0),\n",
    "        [3, 3])\n",
    "\n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape(\n",
    "        tf.concat([one, s2, zero, zero, c2, zero, zero, zero, one], axis=0),\n",
    "        [3, 3])\n",
    "\n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = tf.reshape(\n",
    "        tf.concat([\n",
    "            one / height_zoom, zero, zero, zero, one / width_zoom, zero, zero,\n",
    "            zero, one\n",
    "        ],\n",
    "                  axis=0), [3, 3])\n",
    "\n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = tf.reshape(\n",
    "        tf.concat(\n",
    "            [one, zero, height_shift, zero, one, width_shift, zero, zero, one],\n",
    "            axis=0), [3, 3])\n",
    "\n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix),\n",
    "                 K.dot(zoom_matrix, shift_matrix))\n",
    "\n",
    "\n",
    "def transform(image, cfg):\n",
    "    \n",
    "    ''' This function takes input images of [: , :, 3] sizes and returns them as randomly rotated, sheared, shifted and zoomed. '''\n",
    "\n",
    "    DIM = cfg['img_size']\n",
    "    XDIM = DIM % 2  # fix for size 331\n",
    "\n",
    "    rot = cfg['rot'] * tf.random.normal([1], dtype='float32')\n",
    "    shr = cfg['shr'] * tf.random.normal([1], dtype='float32')\n",
    "    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / cfg['hzoom']\n",
    "    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / cfg['wzoom']\n",
    "    h_shift = cfg['hshift'] * tf.random.normal([1], dtype='float32')\n",
    "    w_shift = cfg['wshift'] * tf.random.normal([1], dtype='float32')\n",
    "\n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot, shr, h_zoom, w_zoom, h_shift, w_shift)\n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat(tf.range(DIM // 2, -DIM // 2, -1), DIM)\n",
    "    y = tf.tile(tf.range(-DIM // 2, DIM // 2), [DIM])\n",
    "    z = tf.ones([DIM * DIM], dtype='int32')\n",
    "    idx = tf.stack([x, y, z])\n",
    "\n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n",
    "    idx2 = K.cast(idx2, dtype='int32')\n",
    "    idx2 = K.clip(idx2, -DIM // 2 + XDIM + 1, DIM // 2)\n",
    "\n",
    "    # FIND ORIGIN PIXEL VALUES\n",
    "    idx3 = tf.stack([DIM // 2 - idx2[0, ], DIM // 2 - 1 + idx2[1, ]])\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "\n",
    "    return tf.reshape(d, [DIM, DIM, 3])\n",
    "\n",
    "def prepare_image(img, cfg=None, augment=True):\n",
    "    \n",
    "    ''' This function loads the image, resizes it, casts a tensor to a new type float32 in our case, transforms it using the function just above, then applies the augmentations.'''\n",
    "    \n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [cfg['img_size'], cfg['img_size']],\n",
    "                          antialias=True)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "\n",
    "    if augment:\n",
    "        if cfg['transform_prob'] > tf.random.uniform([1], minval=0, maxval=1):\n",
    "            img = transform(img, cfg)\n",
    "\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "        img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        img = tf.image.random_brightness(img, 0.1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions below for reading labeled tfrecords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name': tf.io.FixedLenFeature([], tf.string),\n",
    "        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sex': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'age_approx': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'diagnosis': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'target': tf.io.FixedLenFeature([], tf.int64),\n",
    "        #'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        #'height': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    return example['image'], example['target']\n",
    "\n",
    "\n",
    "def read_unlabeled_tfrecord(example):\n",
    "    UNLABELED_TFREC_FORMAT = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name': tf.io.FixedLenFeature([], tf.string),\n",
    "        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sex': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'age_approx': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
    "    return example['image'], example['image_name']\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    n = [\n",
    "        int(re.compile(r'-([0-9]*)\\.').search(filename).group(1))\n",
    "        for filename in filenames\n",
    "    ]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainDataset(files, cfg, augment=True, shuffle=True):\n",
    "    \n",
    "    ''' This function reads the tfrecord train images, shuffles them, apply augmentations to them and prepares the data for training. '''\n",
    "    \n",
    "    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n",
    "    ds = ds.cache()\n",
    "\n",
    "    if shuffle:\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        ds = ds.with_options(opt)\n",
    "\n",
    "    ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    ds = ds.repeat()\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(2048)\n",
    "    ds = ds.map(lambda img, label:\n",
    "                (prepare_image(img, augment=augment, cfg=cfg), label),\n",
    "                num_parallel_calls=AUTO)\n",
    "    ds = ds.batch(cfg['batch_size'] * strategy.num_replicas_in_sync)\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    return ds\n",
    "\n",
    "def getTestDataset(files, cfg, augment=False, repeat=False):\n",
    "    \n",
    "    ''' This function reads the tfrecord test images and prepares the data for predicting. '''\n",
    "    \n",
    "    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n",
    "    ds = ds.cache()\n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "    ds = ds.map(read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    ds = ds.map(lambda img, idnum:\n",
    "                (prepare_image(img, augment=augment, cfg=cfg), idnum),\n",
    "                num_parallel_calls=AUTO)\n",
    "    ds = ds.batch(cfg['batch_size'] * strategy.num_replicas_in_sync)\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    return ds\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    ''' This function gets the layers inclunding efficientnet ones. '''\n",
    "    \n",
    "    model_input = tf.keras.Input(shape=(cfg['img_size'], cfg['img_size'], 3),\n",
    "                                 name='img_input')\n",
    "\n",
    "    dummy = tf.keras.layers.Lambda(lambda x: x)(model_input)\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    x = efn.EfficientNetB3(include_top=False,\n",
    "                           weights='noisy-student',\n",
    "                           input_shape=(cfg['img_size'], cfg['img_size'], 3),\n",
    "                           pooling='avg')(dummy)\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    outputs.append(x)\n",
    "\n",
    "    x = efn.EfficientNetB4(include_top=False,\n",
    "                           weights='noisy-student',\n",
    "                           input_shape=(cfg['img_size'], cfg['img_size'], 3),\n",
    "                           pooling='avg')(dummy)\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    outputs.append(x)\n",
    "\n",
    "    x = efn.EfficientNetB5(include_top=False,\n",
    "                           weights='noisy-student',\n",
    "                           input_shape=(cfg['img_size'], cfg['img_size'], 3),\n",
    "                           pooling='avg')(dummy)\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    outputs.append(x)\n",
    "\n",
    "    model = tf.keras.Model(model_input, outputs, name='aNetwork')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileNewModel(cfg):\n",
    "    \n",
    "    ''' Configuring the model with losses and metrics. '''    \n",
    "    \n",
    "#     with strategy.scope():\n",
    "#         model = get_model()\n",
    "\n",
    "    with strategy.scope():\n",
    "        model = get_model()\n",
    "        model.compile(optimizer=cfg['optimizer'],\n",
    "                      loss=[\n",
    "                          tf.keras.losses.BinaryCrossentropy(\n",
    "                              label_smoothing=cfg['label_smooth_fac']),\n",
    "                          tf.keras.losses.BinaryCrossentropy(\n",
    "                              label_smoothing=cfg['label_smooth_fac']),\n",
    "                          tf.keras.losses.BinaryCrossentropy(\n",
    "                              label_smoothing=cfg['label_smooth_fac'])\n",
    "                      ],\n",
    "                      metrics=[tf.keras.metrics.AUC(name='auc')])\n",
    "    return model\n",
    "\n",
    "def getLearnRateCallback(cfg):\n",
    "    \n",
    "    ''' Using callbacks for learning rate adjustments. '''\n",
    "    \n",
    "    lr_start = cfg['lr_start']\n",
    "    lr_max = cfg['lr_max'] * strategy.num_replicas_in_sync * cfg['batch_size']\n",
    "    lr_min = cfg['lr_min']\n",
    "    lr_rampup = cfg['lr_rampup']\n",
    "    lr_sustain = cfg['lr_sustain']\n",
    "    lr_decay = cfg['lr_decay']\n",
    "\n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_rampup:\n",
    "            lr = (lr_max - lr_start) / lr_rampup * epoch + lr_start\n",
    "        elif epoch < lr_rampup + lr_sustain:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_rampup -\n",
    "                                                lr_sustain) + lr_min\n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###  def learnModel(model, ds_train, stepsTrain, cfg):\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "# GCS_PATH2 = KaggleDatasets().get_gcs_path('isic2019-384x384')\n",
    "# INC2019 = INC2018 = False\n",
    "# FOLDS = 5\n",
    "# skf = KFold(n_splits=FOLDS,shuffle=True,random_state=seed_val)\n",
    "\n",
    "# files_test = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/test*.tfrec')))\n",
    "# stepsTest = count_data_items(files_test) / (cfg['batch_size'] * strategy.num_replicas_in_sync)\n",
    "# z = np.zeros((cfg['batch_size'] * strategy.num_replicas_in_sync))\n",
    "# ds_testAug = getTestDataset(files_test, cfg, augment=True, repeat=True).map(lambda img, label: (img, (z, z, z)))\n",
    "\n",
    "# test_probs = []\n",
    "# for fold, (idxT, idxV) in enumerate(skf.split(np.arange(15))):\n",
    "#     if fold not in [0]: continue\n",
    "    \n",
    "#     files_train = tf.io.gfile.glob([GCS_PATH + '/train%.2i*.tfrec'%x for x in idxT])\n",
    "#     files_valid = tf.io.gfile.glob([GCS_PATH + '/train%.2i*.tfrec'%x for x in idxV])\n",
    "#     print('#### Using original data')\n",
    "#     print('files_train #:', len(files_train))\n",
    "    \n",
    "#     if INC2019:\n",
    "#         files_train += tf.io.gfile.glob([GCS_PATH2 + '/train%.2i*.tfrec'%x for x in idxT*2+1])\n",
    "#         print('#### Add 2019 external data')\n",
    "#         print('files_train #:', len(files_train))\n",
    "#     if INC2018:\n",
    "#         files_train += tf.io.gfile.glob([GCS_PATH2 + '/train%.2i*.tfrec'%x for x in idxT*2])\n",
    "#         print('#### Add 2018 external data')\n",
    "#         print('files_train #:', len(files_train))\n",
    "    \n",
    "#     stepsTrain = count_data_items(files_train) / (cfg['batch_size'] * strategy.num_replicas_in_sync)\n",
    "#     stepsValid = count_data_items(files_valid) / (cfg['batch_size'] * strategy.num_replicas_in_sync)\n",
    "    \n",
    "#     ds_train = getTrainDataset(files_train, cfg, augment=True, shuffle=True).map(lambda img, label: (img, (label, label, label)))\n",
    "#     ds_valid = getTrainDataset(files_valid, cfg, augment=False, shuffle=False).map(lambda img, label: (img, (label, label, label)))\n",
    "        \n",
    "#     K.clear_session()\n",
    "#     with strategy.scope():\n",
    "#         model = compileNewModel(cfg)\n",
    "        \n",
    "#     sv = tf.keras.callbacks.ModelCheckpoint( # val_loss\n",
    "#         'auc_fold%i_e{epoch}.h5'%fold, monitor='val_dense_auc', verbose=0, save_best_only=False,\n",
    "#         save_weights_only=True, mode='max', save_freq='epoch')\n",
    "\n",
    "#     callbacks = [sv, getLearnRateCallback(cfg)]\n",
    "#     history = model.fit(ds_train,\n",
    "#                         validation_data=ds_valid,\n",
    "#                         verbose=1,\n",
    "#                         steps_per_epoch=stepsTrain,\n",
    "#                         validation_steps=stepsValid,\n",
    "#                         epochs=cfg['epochs'],\n",
    "#                         callbacks=callbacks)\n",
    "    \n",
    "\n",
    "# #     # test time augmentations for predictions (20 in our case, you can increase it a little in cfg) and taking mean of them\n",
    "# #     probs = model.predict(ds_testAug, verbose=1, steps=stepsTest * cfg['tta_steps'])\n",
    "# #     probs = np.stack(probs)\n",
    "# #     probs = probs[:, :count_data_items(filenames_test) * cfg['tta_steps']]\n",
    "# #     probs = np.stack(np.split(probs, cfg['tta_steps'], axis=1), axis=1)\n",
    "# #     test_probs.append(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY_PLOT = True\n",
    "# if DISPLAY_PLOT:\n",
    "#     plt.figure(figsize=(15,5))\n",
    "#     plt.plot(np.arange(cfg['epochs']),history.history['dense_auc'],'-o',label='Train AUC',color='#ff7f0e')\n",
    "#     plt.plot(np.arange(cfg['epochs']),history.history['val_dense_auc'],'-o',label='Val AUC',color='#1f77b4')\n",
    "#     x = np.argmax( history.history['val_dense_auc'] ); y = np.max( history.history['val_dense_auc'] )\n",
    "#     xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "#     plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.2f'%y,size=14)\n",
    "#     plt.ylabel('AUC',size=14); plt.xlabel('Epoch',size=14)\n",
    "#     plt.legend(loc=2)\n",
    "#     plt2 = plt.gca().twinx()\n",
    "#     plt2.plot(np.arange(cfg['epochs']),history.history['dense_loss'],'-o',label='Train Loss',color='#2ca02c')\n",
    "#     plt2.plot(np.arange(cfg['epochs']),history.history['val_dense_loss'],'-o',label='Val Loss',color='#d62728')\n",
    "#     x = np.argmin( history.history['val_dense_loss'] ); y = np.min( history.history['val_dense_loss'] )\n",
    "#     ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "#     plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n",
    "#     plt.ylabel('Loss',size=14)\n",
    "# #     plt.title('FOLD %i - Image Size %i, EfficientNet B%i, inc2019=%i, inc2018=%i'%\n",
    "# #             (fold+1,IMG_SIZES[fold],EFF_NETS[fold],INC2019[fold],INC2018[fold]),size=18)\n",
    "#     plt.legend(loc=3)\n",
    "#     plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# model.load_weights('./auc_fold3_e13.h5')\n",
    "# probs = model.predict(ds_testAug, verbose=1, steps=stepsTest * cfg['tta_steps'])\n",
    "# probs = np.stack(probs)\n",
    "# probs = probs[:, :count_data_items(filenames_test) * cfg['tta_steps']]\n",
    "# probs = np.stack(np.split(probs, cfg['tta_steps'], axis=1), axis=1)\n",
    "# test_probs.append(probs)\n",
    "\n",
    "# file = open('test_probs_3', 'wb')\n",
    "# pickle.dump(test_probs, file)\n",
    "# file.close()\n",
    "\n",
    "# fp = ['../input/test-probs/test_probs_0', '../input/test-probs/test_probs_1',\n",
    "#      '../input/test-probs/test_probs_2', '../input/test-probs/test_probs_3',\n",
    "#      '../input/test-probs/test_probs_4']\n",
    "\n",
    "# all_test_probs = []\n",
    "# for f in fp:\n",
    "#     file = open(f, 'rb')\n",
    "#     test_probs = pickle.load(file)\n",
    "#     all_test_probs += test_probs\n",
    "#     file.close()\n",
    "\n",
    "# len(all_test_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs = np.mean(all_test_probs, axis=0)\n",
    "# probs = np.mean(probs, axis=1)\n",
    "# test = pd.read_csv(os.path.join(base_path, 'test.csv'))\n",
    "\n",
    "# y_test_sorted = np.zeros((3, probs.shape[1]))\n",
    "# test = test.reset_index()\n",
    "# test = test.set_index('image_name')\n",
    "\n",
    "# i = 0\n",
    "# ds_test = getTestDataset(filenames_test, cfg)\n",
    "# for img, imgid in tqdm(iter(ds_test.unbatch())):\n",
    "#     imgid = imgid.numpy().decode('utf-8')\n",
    "#     y_test_sorted[:, test.loc[imgid]['index']] = probs[:, i, 0]\n",
    "#     i += 1\n",
    "\n",
    "    \n",
    "# # creating .csv files for each effnet\n",
    "\n",
    "# sample = pd.read_csv(os.path.join(base_path, 'sample_submission.csv'))\n",
    "# # for i in range(y_test_sorted.shape[0]):\n",
    "# #     submission = sample\n",
    "# #     submission['target'] = y_test_sorted[i]\n",
    "# #     submission.to_csv('submission_model_%s.csv' % i, index=False)\n",
    "\n",
    "# # blending effnets into a single .csv file    \n",
    "\n",
    "# submission = sample\n",
    "# submission['target'] = np.mean(y_test_sorted, axis=0)\n",
    "# submission.to_csv('blended_effnets_auc_5fold.csv', index=False)\n",
    "\n",
    "# # loading recently created .csv files from working directory\n",
    "\n",
    "# effnet = pd.read_csv('./blended_effnets_auc_5fold.csv')\n",
    "# meta = pd.read_csv('../input/sscsv/meta_simplified_img_data.csv')\n",
    "\n",
    "# sample['target'] = (effnet['target'] * 0.9 + meta['target'] * 0.1 )\n",
    "\n",
    "# # final submissions\n",
    "\n",
    "# sample.to_csv('ensembled_auc_5fold.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnModel(model, ds_train, stepsTrain, cfg, ds_val=None, stepsVal=0):\n",
    "    \n",
    "    ''' Fitting things together for training '''\n",
    "    \n",
    "    # callbacks = [getLearnRateCallback(cfg)]\n",
    "\n",
    "    sv = tf.keras.callbacks.ModelCheckpoint( # val_loss\n",
    "        'auc_e{epoch}.h5', monitor='val_dense_auc', verbose=0, save_best_only=False,\n",
    "        save_weights_only=True, mode='max', save_freq='epoch')\n",
    "\n",
    "    callbacks = [sv, getLearnRateCallback(cfg)]\n",
    "    \n",
    "    history = model.fit(ds_train,\n",
    "                        validation_data=ds_val,\n",
    "                        verbose=1,\n",
    "                        steps_per_epoch=stepsTrain,\n",
    "                        validation_steps=stepsVal,\n",
    "                        epochs=cfg['epochs'],\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "    return history\n",
    "\n",
    "GCS_PATH2 = KaggleDatasets().get_gcs_path('isic2019-384x384')\n",
    "INC2019_2018 = False\n",
    "\n",
    "files_train = tf.io.gfile.glob([GCS_PATH + '/train*.tfrec'])\n",
    "print('#### Using original data')\n",
    "print('files_train #:', len(files_train))\n",
    "\n",
    "if INC2019_2018: \n",
    "    files_train += tf.io.gfile.glob(GCS_PATH2 + '/train*.tfrec')\n",
    "    print('#### Add external data')\n",
    "    print('files_train #:', len(files_train))\n",
    "\n",
    "ds_train = getTrainDataset(files_train, cfg, augment=True, shuffle=True).map(lambda img, label: (img, (label, label, label)))\n",
    "\n",
    "stepsTrain = count_data_items(files_train) / (cfg['batch_size'] * strategy.num_replicas_in_sync)\n",
    "\n",
    "model = compileNewModel(cfg)\n",
    "history = learnModel(model, ds_train, stepsTrain, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(np.arange(cfg['epochs']),history.history['dense_auc'],'-o',label='Train AUC',color='#ff7f0e')\n",
    "#plt.plot(np.arange(cfg['epochs']),history.history['val_dense_auc'],'-o',label='Val AUC',color='#1f77b4')\n",
    "x = np.argmax( history.history['dense_auc'] )\n",
    "y = np.max( history.history['dense_auc'] )\n",
    "xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.2f'%y,size=14)\n",
    "plt.ylabel('AUC',size=14); plt.xlabel('Epoch',size=14)\n",
    "plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"aNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_input (InputLayer)          [(None, 384, 384, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 384, 384, 3)  0           img_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b3 (Model)         (None, 1536)         10783528    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b4 (Model)         (None, 1792)         17673816    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b5 (Model)         (None, 2048)         28513520    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            1537        efficientnet-b3[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            1793        efficientnet-b4[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            2049        efficientnet-b5[1][0]            \n",
      "==================================================================================================\n",
      "Total params: 56,976,243\n",
      "Trainable params: 56,591,011\n",
      "Non-trainable params: 385,232\n",
      "__________________________________________________________________________________________________\n",
      "858/857 [==============================] - 295s 344ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10982it [00:26, 411.64it/s]\n"
     ]
    }
   ],
   "source": [
    "model = compileNewModel(cfg)\n",
    "model.load_weights('../input/ssweights/auc_e13.h5')\n",
    "\n",
    "files_test = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/test*.tfrec')))\n",
    "steps = count_data_items(files_test) / (cfg['batch_size'] * strategy.num_replicas_in_sync)\n",
    "z = np.zeros((cfg['batch_size'] * strategy.num_replicas_in_sync))\n",
    "\n",
    "# loading test data\n",
    "\n",
    "ds_testAug = getTestDataset(files_test, cfg, augment=True, repeat=True).map(lambda img, label: (img, (z, z, z)))\n",
    "\n",
    "# test time augmentations for predictions (20 in our case, you can increase it a little in cfg) and taking mean of them\n",
    "\n",
    "probs = model.predict(ds_testAug, verbose=1, steps=steps * cfg['tta_steps'])\n",
    "probs = np.stack(probs)\n",
    "probs = probs[:, :count_data_items(filenames_test) * cfg['tta_steps']]\n",
    "probs = np.stack(np.split(probs, cfg['tta_steps'], axis=1), axis=1)\n",
    "probs = np.mean(probs, axis=1)\n",
    "\n",
    "test = pd.read_csv(os.path.join(base_path, 'test.csv'))\n",
    "\n",
    "y_test_sorted = np.zeros((3, probs.shape[1]))\n",
    "test = test.reset_index()\n",
    "test = test.set_index('image_name')\n",
    "\n",
    "i = 0\n",
    "ds_test = getTestDataset(filenames_test, cfg)\n",
    "for img, imgid in tqdm(iter(ds_test.unbatch())):\n",
    "    imgid = imgid.numpy().decode('utf-8')\n",
    "    y_test_sorted[:, test.loc[imgid]['index']] = probs[:, i, 0]\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "# creating .csv files for each effnet\n",
    "sample = pd.read_csv(os.path.join(base_path, 'sample_submission.csv'))\n",
    "# for i in range(y_test_sorted.shape[0]):\n",
    "#     submission = sample\n",
    "#     submission['target'] = y_test_sorted[i]\n",
    "#     submission.to_csv('submission_model_%s.csv' % i, index=False)\n",
    "\n",
    "# blending effnets into a single .csv file    \n",
    "\n",
    "submission = sample\n",
    "submission['target'] = np.mean(y_test_sorted, axis=0)\n",
    "submission.to_csv('blended_effnets.csv', index=False)\n",
    "\n",
    "# loading recently created .csv files from working directory\n",
    "\n",
    "effnet = pd.read_csv('./blended_effnets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use blended_effnets.csv in https://www.kaggle.com/datafan07/eda-modelling-of-the-external-data-inc-ensemble to get eda_ensembled.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use eda_ensembled.csv in https://www.kaggle.com/paklau9/minmax-highest-public-lb-9619 to get final submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./submission_mean.csv'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.copy('../input/cs0099/submission.csv', './submission.csv')\n",
    "shutil.copy('../input/cs0099/submission_6.csv', './submission_6.csv')\n",
    "shutil.copy('../input/cs0099/submission_jig.csv', './submission_jig.csv')\n",
    "shutil.copy('../input/cs0099/submission_mean.csv', './submission_mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os \n",
    "\n",
    "def MinMaxBestBaseStacking(input_folder, best_base, output_path):\n",
    "    sub_base = pd.read_csv(best_base)\n",
    "    all_files = os.listdir(input_folder)\n",
    "\n",
    "    # Read and concatenate submissions\n",
    "    outs = [pd.read_csv(os.path.join(input_folder, f), index_col=0) for f in all_files]\n",
    "    concat_sub = pd.concat(outs, axis=1)\n",
    "    cols = list(map(lambda x: \"target\" + str(x), range(len(concat_sub.columns))))\n",
    "    concat_sub.columns = cols\n",
    "    concat_sub.reset_index(inplace=True)\n",
    "\n",
    "    print(concat_sub)\n",
    "    print(concat_sub.iloc[:, 1:6])\n",
    "    # get the data fields ready for stacking\n",
    "    concat_sub['is_iceberg_max'] = concat_sub.iloc[:, 1:6].max(axis=1)\n",
    "    concat_sub['is_iceberg_min'] = concat_sub.iloc[:, 1:6].min(axis=1)\n",
    "    concat_sub['is_iceberg_mean'] = concat_sub.iloc[:, 1:6].mean(axis=1)\n",
    "    concat_sub['is_iceberg_median'] = concat_sub.iloc[:, 1:6].median(axis=1)\n",
    "\n",
    "    # set up cutoff threshold for lower and upper bounds\n",
    "    cutoff_lo = 0.66\n",
    "    cutoff_hi = 0.33\n",
    "    \n",
    "#     cutoff_lo = 0.85\n",
    "#     cutoff_hi = 0.17\n",
    "\n",
    "    concat_sub['is_iceberg_base'] = sub_base['target']\n",
    "    concat_sub['target'] = np.where(np.all(concat_sub.iloc[:, 1:6] > cutoff_lo, axis=1),\n",
    "                                        concat_sub['is_iceberg_max'],\n",
    "                                        np.where(np.all(concat_sub.iloc[:, 1:6] < cutoff_hi, axis=1),\n",
    "                                                 concat_sub['is_iceberg_min'],\n",
    "                                                 concat_sub['is_iceberg_base']))\n",
    "    concat_sub[['image_name', 'target']].to_csv(output_path,\n",
    "                                            index=False, float_format='%.12f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         image_name   target0   target1   target2   target3\n",
      "0      ISIC_0052060  0.012047  0.032010  0.026612  0.022257\n",
      "1      ISIC_0052349  0.009849  0.025807  0.023487  0.016384\n",
      "2      ISIC_0058510  0.012835  0.027831  0.023767  0.023354\n",
      "3      ISIC_0073313  0.010287  0.030409  0.024287  0.017497\n",
      "4      ISIC_0073502  0.011848  0.029881  0.027824  0.018092\n",
      "...             ...       ...       ...       ...       ...\n",
      "10977  ISIC_9992485  0.008851  0.029353  0.019685  0.012813\n",
      "10978  ISIC_9996992  0.027116  0.028810  0.035447  0.020065\n",
      "10979  ISIC_9997917  0.054770  0.040276  0.049058  0.062400\n",
      "10980  ISIC_9998234  0.013760  0.028119  0.029427  0.026082\n",
      "10981  ISIC_9999302  0.056559  0.056665  0.047329  0.080993\n",
      "\n",
      "[10982 rows x 5 columns]\n",
      "        target0   target1   target2   target3\n",
      "0      0.012047  0.032010  0.026612  0.022257\n",
      "1      0.009849  0.025807  0.023487  0.016384\n",
      "2      0.012835  0.027831  0.023767  0.023354\n",
      "3      0.010287  0.030409  0.024287  0.017497\n",
      "4      0.011848  0.029881  0.027824  0.018092\n",
      "...         ...       ...       ...       ...\n",
      "10977  0.008851  0.029353  0.019685  0.012813\n",
      "10978  0.027116  0.028810  0.035447  0.020065\n",
      "10979  0.054770  0.040276  0.049058  0.062400\n",
      "10980  0.013760  0.028119  0.029427  0.026082\n",
      "10981  0.056559  0.056665  0.047329  0.080993\n",
      "\n",
      "[10982 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#MinMaxBestBaseStacking('../input/cs0099/', '../input/cs0099/submission_mean.csv', 'submission.csv')\n",
    "MinMaxBestBaseStacking('../input/ss-minmax-csv/', '../input/sscsv/eda_ensembled.csv', 'submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
